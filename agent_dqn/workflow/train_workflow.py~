import torch
from datetime import datetime
from tqdm import tqdm
from itertools import count
from agent_dqn.agent import Agent
from agent_dqn.conf.conf import Config
from env import envManager


def train_workflow(agent: Agent, env: envManager, num_episodes=Config.NUM_EPISODES):
    """
    训练流程
    :param agent:
    :param env:
    :param num_episodes:
    :return:
    """
    # 遍历episode
    for episode in tqdm(range(num_episodes)):
        total_reward = 0
        # 重置环境
        env.reset()
        # 得到状态
        state = env.get_state()
        for duration in count():
            action = agent.predict(state)
            reward = env.take_action(action)
            next_state = env.get_state()
            # 当步长超过500或杆子与竖直方向偏离超过一定角度，或者小车位置超出轨道边界时，环境结束
            env.done = torch.tensor([env.done or duration > 500]).float().to(agent.device)
            # 向经验池填充经验
            agent.algorithm.memory_push(Config.Experience(state, action, next_state, reward, env.done))
            state = next_state
            total_reward += reward
            # 环境结束，向监控器填充此次episode信息
            if env.done:
                agent.monitor.add_duration_info(duration)
                agent.monitor.add_reward_info(total_reward)
                break

        if agent.algorithm.can_sample():
            # 从经验池中采样
            experiences = agent.algorithm.memory_sample()
            # 训练主网络以及更新目标网络
            agent.learn(experiences)


def test_episodes(num_episodes: int, agent: Agent, env: envManager):
    for episode in tqdm(range(num_episodes)):
        total_reward = 0
        env.reset()
        state = env.get_state()
        for duration in count():
            action = agent.predict(state, exploit_flag=True)
            reward = env.take_action(action)
            total_reward += reward
            next_state = env.get_state()
            env.done = torch.tensor([env.done or duration > 500]).float().to(agent.device)
            state = next_state
            if env.done or duration > 500:
                agent.monitor.add_duration_info(duration)
                agent.monitor.add_reward_info(total_reward)
                break
